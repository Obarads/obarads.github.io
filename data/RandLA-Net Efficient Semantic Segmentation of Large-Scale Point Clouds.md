# RandLA-Net: Efficient Semantic Segmentation of Large-Scale Point Clouds

Update: 2023/06/22

## â„¹ï¸ Info
- Paper: [arxiv.org](https://arxiv.org/abs/1911.11236)
  - Submission date: 2019/11/25
  - Authors: Qingyong Hu, Bo Yang, Linhai Xie, Stefano Rosa, Yulan Guo, Zhihua Wang, Niki Trigoni, Andrew Markham
  - Conf.: CVPR 2020
- Implementation: [QingyongHu/RandLA-Net](https://github.com/QingyongHu/RandLA-Net)
  - framework: Tensorflow
  - Official code: Yes
  - License: Attribution-NonCommercial-ShareAlike 4.0 International
- Keywords: CV, Point Cloud, Semantic Segmentation

## ğŸ–¥ï¸ Setup commands to run the implementation
### 1. Create a docker container
```bash
# Set this repository absolute path (ex: /home/user/obarads.github.io)
git clone https://github.com/Obarads/obarads.github.io.git
cd obarads.github.io
OGI_DIR_PATH=$PWD

# Create a base image with cuda 9.0, cudnn 7.6, and ubuntu 16.04
ENV_VERSION=cuda9.0_cudnn7.6_ubuntu16.04
BASE_IMAGE=ogi_cuda:$ENV_VERSION
docker build . -t $BASE_IMAGE  -f $OGI_DIR_PATH/public/data/envs/cuda/$ENV_VERSION/Dockerfile 

# Create and move to a container dir
mkdir containers
cd containers
# Clone the repository
git clone https://github.com/QingyongHu/RandLA-Net
# Move to RandLA-Net
cd RandLA-Net
# Switch to 2021/07/02 ver.
git switch -d 6b5445f5f279d33d2335e85ed39ca8b68cb1c57e
# Copy a folder for building env.
cp -r $OGI_DIR_PATH/environments/RESSoLPC/ ./dev_env

# Create docker image and container
docker build . -t randla_net -f ./dev_env/Dockerfile --build-arg UID=$(id -u) --build-arg GID=$(id -g) --build-arg BASE_IMAGE=$BASE_IMAGE
docker run -dit --name randla_net --gpus all -v $PWD:/workspace randla_net
```

### 2. Setup packages
In a docker container:
```bash
cd /workspace

conda create -n randlanet python=3.6 # for PyYAML=5.4
conda activate randlanet

cd dev_env
pip install -r requirements.txt 

cd ../
sh compile_op.sh
```

### 3. Setup the dataset
Please refer to [the section of README.md](https://github.com/QingyongHu/RandLA-Net/tree/6b5445f5f279d33d2335e85ed39ca8b68cb1c57e#2-s3dis) for the [S3DIS dataset](https://docs.google.com/forms/d/e/1FAIpQLScDimvNMCGhy_rmBA2gHfDu3naktRm6A8BPwAWWDv-Uhm6Shw/viewform?c=0&w=1) preparation (`/data/S3DIS/Stanford3dDataset_v1.2_Aligned_Version/` dir) into the docker container, and then run the following commands :
```bash
# setup a dataset for semantic segmentation
sudo chmod -R 777 /data/
python utils/data_prepare_s3dis.py
```

### 4. Run a model
In a docker container:
```bash
cd /workspace
sh jobs_6_fold_cv_s3dis.sh
```

## ğŸ“ Clipping and note
### ã©ã‚“ãªã‚‚ã®?
- å¤§è¦æ¨¡ç‚¹ç¾¤ã«å¯¾ã™ã‚‹è»½é‡ãªãƒ¢ãƒ‡ãƒ«ã€RandLA-Netã‚’ææ¡ˆã—ãŸã€‚
- æ—¢å­˜ã®æ‰‹æ³•ã‚ˆã‚Šã‚‚æœ€å¤§200å€æ—©ã„ã€‚ã¾ãŸã€100ä¸‡ç‚¹ã«å¯¾ã™ã‚‹å‡¦ç†ã‚‚ä¸€å›ã®å…¥åŠ›ã§å‡¦ç†ã§ãã‚‹ã€‚ã“ã‚Œã¯æ—¢å­˜ã®æ‰‹æ³•ã‚ˆã‚Šã‚‚ã€ä¸€åº¦ã«å¤šãã®ç‚¹ã‚’å‡¦ç†ã§ãã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚
  - lage-scaleç‚¹ç¾¤ã‚’å‡¦ç†ã™ã‚‹æ‰‹æ³•ã¯ã‚ã‚‹ãŒã€ã“ã‚Œã‚‰ã¯ãƒœã‚¯ã‚»ãƒ«åŒ–ã‚„SPGåŒ–ãªã©ã®å‰å‡¦ç†ã§æ™‚é–“ãŒã‹ã‹ã‚‹ã€‚
- è¤‡é›‘ãªç‚¹é¸æŠã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®ä»£ã‚ã‚Šã«ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒã“ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã®é‡è¦ãªç‚¹ã§ã‚ã‚‹ã€‚
- ææ¡ˆã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯å›³3ã®é€šã‚Šã€‚ã“ã‚Œã‚’åˆ©ç”¨ã—ãŸãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚‹RandLA-Netã¯å›³7ã®é€šã‚Šã€‚
  - æœ¬ææ¡ˆã§ã¯ã€ä½™åˆ†ãªãƒ¡ãƒ¢ãƒªã‚’å¿…è¦ã¨ã›ãšã€è¨ˆç®—ã‚³ã‚¹ãƒˆãŒåœ§å€’çš„ã«ä½ã„ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°($\mathcal{O}(1)$)ã‚’ä½¿ç”¨ã™ã‚‹ã€‚
  - ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¯æœ‰ç”¨ãªç‚¹ç‰¹å¾´ã‚’æ¨ã¦ã¦ã—ã¾ã†æã‚ŒãŒã‚ã‚‹ãŸã‚ã€å•é¡Œã‚’å…‹æœã™ã‚‹ãŸã‚ã«ã€ãƒ­ãƒ¼ã‚«ãƒ«ç‰¹å¾´é›†ç´„æ©Ÿæ§‹ã§ã‚ã‚‹Local Feature Aggregationãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ææ¡ˆã™ã‚‹ã€‚

![fig3](img/RESSoLPC/fig3.png)

> Figure 3. The proposed local feature aggregation module. The top panel shows the location spatial encoding block that extracts features, and the attentive pooling mechanism that weights the most important neighbouring features, based on the local context and geometry. The bottom panel shows how two of these components are chained together, to increase the receptive field size, within a residual block.

![fig7](img/RESSoLPC/fig7.png)

> Figure 7. The detailed architecture of our RandLA-Net. (N, D) represents the number of points and feature dimension respectively. FC: Fully Connected layer, LFA: Local Feature Aggregation, RS: Random Sampling, MLP: shared Multi-Layer Perceptron, US: Up-sampling, DP: Dropout.

### ã©ã†ã‚„ã£ã¦æœ‰åŠ¹ã ã¨æ¤œè¨¼ã—ãŸ?
- SemanticKITTIã«ã‚ˆã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æ¤œè¨¼ (table 2)
- Semantic3Dã«ã‚ˆã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æ¤œè¨¼ (table 3)

![tab2](img/RESSoLPC/tab2.png)

> Table 2. Quantitative results of different approaches on Semantic3D (reduced-8) [17]. Only the recent published approaches are compared. Accessed on 31 March 2020.

![tab3](img/RESSoLPC/tab3.png)

> Table 3. Quantitative results of different approaches on SemanticKITTI [3]. Only the recent published methods are compared and all scores are obtained from the online single scan evaluation track. Accessed on 31 March 2020.

## ğŸ“š è«–æ–‡é–¢é€£ãƒªãƒ³ã‚¯
ãªã—
