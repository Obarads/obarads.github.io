# Complexer-YOLO: Real-Time 3D Object Detection and Tracking on Semantic Point Clouds

元の論文の公開ページ : [openaccess.thecvf.com](http://openaccess.thecvf.com/content_CVPRW_2019/papers/Autonomous%20Driving/Simon_Complexer_YOLO_Real-Time_3D_Object_Detection_and_Tracking_on_Semantic_CVPRW_2019_paper.pdf)  
提案モデルの実装 : [2020/1/11:なし]()  
Github Issues : []()  

Note: 記事の見方や注意点については、[こちら](/)をご覧ください。

## どんなもの?
##### オブジェクトのトラッキングが可能なリアルタイム3Dオブジェクト検出モデル、Complexer-YOLOを提案した。
- Complex-YOLOに更に機能や新たな提案を追加したモデルである。

##### 新たな3Dバウンディングボックスの計測基準、Scale-Rotation-Translation score (SRTs)を提案した。
- IoUよりも早く計算が可能である。
  - 推論時間を最大20%、訓練時間を半分短縮する。
- 幅、高さ、長さ、ヨー角を含む、検出されたオブジェクトの3DoFの姿勢を考慮する。

## 先行研究と比べてどこがすごいの? or 関連事項
##### 省略

## 技術や手法のキモはどこ? or 提案手法の詳細
##### 省略

## どうやって有効だと検証した?
##### 省略

## 議論はある?
##### 省略

## 次に読むべき論文は?
##### なし

## 論文関連リンク
##### なし
1. [なし]()[1]

## 会議, 論文誌, etc.
##### CVPR 2019 WS

## 著者
##### Martin Simon, Karl Amende, Andrea Kraus, Jens Honer, Timo Sämann, Hauke Kaulbersch, Stefan Milz, Horst Michael Gross.

## 投稿日付(yyyy/MM/dd)
##### 2019/04/16

## コメント
##### あり
- まだ

## key-words
##### CV, Paper, Point_Cloud, Detection, 導入, Semantic_Segmentation, Sensor_Fusion, RGB_Image, Flow_Estimation

## status
##### 導入

## read
##### A, I

## Citation
##### 未記入
